#using the spark-docker image we just created as our base image
FROM newyorker/spark

WORKDIR /tmp

ADD pom.xml /tmp/pom.xml
RUN ["mvn", "clean"]

# Adding source, compile and package into a fat jar
ADD src /code/src

RUN ["mvn", "compile"]
RUN ["mvn", "install"]

#yelp_academic_dataset_review_2.11-1.0.jar is our Fat Jar to be run; here I assume it<92>s in the same build context as the Dockerfile;

COPY /tmp/target/yelp-academic-dataset-review-0.7-jar-with-dependencies.jar /opt/yelp_academic_dataset_review.jar

#calling the spark-submit command; with the --class argument being an input environment variable

CMD /opt/spark/bin/spark-submit --class $SPARK_CLASS --master local[1] /opt/yelp_academic_dataset_review.jar